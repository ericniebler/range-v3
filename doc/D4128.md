<table border="0" cellpadding="0" cellspacing="0" style="border-collapse: collapse" bordercolor="#111111" width="607">
    <tr>
        <td width="172" align="left" valign="top">Document number:</td>
        <td width="435"><span style="background-color: #FFFF00">D4128</span>=yy-nnnn</td>
    </tr>
    <tr>
        <td width="172" align="left" valign="top">Date:</td>
        <td width="435">2014-07-26</td>
    </tr>
    <tr>
        <td width="172" align="left" valign="top">Project:</td>
        <td width="435">Programming Language C++, Library Working Group</td>
    </tr>
    <tr>
        <td width="172" align="left" valign="top">Reply-to:</td>
        <td width="435">Eric Niebler &lt;<a href="mailto:eniebler@boost.org">eniebler@boost.org</a>&gt;</td>
    </tr>
</table>

Ranges for the Standard Library, Revision 1
===========================================

> "A beginning is the time for taking the most delicate care that the balances are correct."

-- Frank Herbert, _Dune_

I. Table of Contents
--------------------

- [II. Introduction](#ii-introduction)
- [III. Motivation and Scope](#iii-motivation-and-scope)
    1. [Impact on the Standard](#impact-on-the-standard)
- [IV. Proposed Design](#iv-proposed-design)
    1. [Design Goals](#design-goals)
    2. [High-Level Design](#high-level-design)
    3. [Design Decisions, Guidelines, and Rationale](#design-decisions-guidelines-and-rationale)
        1. [Iterator Operations Are Primitive](#iterator-operations-are-primitive)
            - [Position-Based Ranges](#position-based-ranges)
        2. [Ranges Cannot Own Elements](#ranges-cannot-own-elements)
        3. [Ranges Are Semiregular](#ranges-are-semiregular)
        4. [Iterators Cannot Outlive Their Ranges](#iterators-cannot-outlive-their-ranges)
        5. [An Iterable's End May Have a Different Type Than Its Begin](#an-iterables-end-may-have-a-different-type-than-its-begin)
            - [Sentinels and Early Algorithm Termination](#sentinels-and-early-algorithm-termination)
        6. [Algorithm Return Types Are Changed To Accomodate Sentinels](#algorithm-return-types-are-changed-to-accomodate-sentinels)
        7. [Orthogonality of Traversal and Access Is Not Surfaced in the Iterator Concepts](#orthogonality-of-traversal-and-access-is-not-surfaced-in-the-iterator-concepts)
        8. [Additional Overloads of the Algorithms](#additional-overloads-of-the-algorithms)
        9. [Range-Based for Loop is Changed to Accomodate Sentinels](#range-based-for-loop-is-changed-to-accomodate-sentinels)
        10. [Allow Mutable-Only Iterables](#allow-mutable-only-iterables)
        11. [Range Adaptors Are Lazy Algorithms](#range-adaptors-are-lazy-algorithms)
        12. [All Algorithms Accept Sentinels Even If They Need An End Iterator](#all-algorithms-accept-sentinels-even-if-they-need-an-end-iterator)
- [V. Concept Definitions](#v-concept-definitions)
    1. [Iterator Concepts](#iterator-concepts)
    2. [Iterator Range Concepts](#iterator-range-concepts)
    3. [Iterable Concepts](#iterable-concepts)
    4. [Sized Iterable Concepts](#sized-iterable-concepts)
- [VI. Technical Specifications](#vi-technical-specifications)
- [VII. Future Directions](#vii-future-directions)
- [VIII. Acknowledgements](#viii-acknowledgements)
- [IX. References](#ix-references)
- [Appendix 1: Sentinels and Code Generation](#appendix-1-sentinels-and-code-generation)
- [Appendix 2: Sentinels, Iterators, and the Cross-Type EqualityComparable Concept](#appendix-2-sentinels-iterators-and-the-cross-type-equalitycomparable-concept)
- [Appendix 3: D Ranges and Algorithmic Complexity](#appendix-3-d-ranges-and-algorithmic-complexity)
- [Appendix 4: On Counted Ranges and Efficiency](#appendix-4-on-counted-ranges-and-efficiency)
    - [Single-Pass Algorithms with Counted Iterators](#single-pass-algorithms-with-counted-iterators)
    - [Multi-Pass Algorithms with Counted Iterators](#multi-pass-algorithms-with-counted-iterators)
    - [Counted Algorithms with Counted Iterators](#counted-algorithms-with-counted-iterators)
- [Appendix 5: Drive-By Improvements to the Standard Algorithms](#appendix-5-drive-by-improvements-to-the-standard-algorithms)
    - [Higher-Order Algorithms Should Take Invokables Instead of Functions](#higher-order-algorithms-should-take-invokables-instead-of-functions)
    - [Algorithms Should Take Invokable Projections](#algorithms-should-take-invokable-projections)
        1. [Projections versus Range Transform View](#projections-versus-range-transform-view)
- [Appendix 6: Implementation Notes](#appendix-6-implementation-notes)
    - [On Distinguishing Ranges from Non-Range Iterables](#on-distinguishing-ranges-from-non-range-iterables)
    - [Native Arrays and Ambiguity](#native-arrays-and-ambiguity)
    - [Algorithm Implementation with Projections](#algorithm-implementation-with-projections)
    - [Algorithms That Need An End Iterator](#algorithms-that-need-an-end-iterator)

II. Introduction
----------------

This paper outlines what support for ranges in the C++ standard library might look like. Rather than presenting a final design, this paper proposes a set of concepts and guidelines for using them to implement range-based versions of the standard algorithms. It draws inspiration from the Boost.Range library, the range algorithms in Adobe Source Libraries, *Elements of Programming* by Stepanov and McJones (2009), and from N3351 "A Concept Design for the STL" by Stroustrup and Sutton (2012). In addition to presenting the concepts and guidelines, this paper discusses the rationale behind each, weighing different design options.

The decision to defer any discussion about specific wording was taken in recognition of the fact that any range design is likely to undergo significant revision by the committee. The paper is intended merely as a starting point for discussion and as a basis for future work.

This paper assumes the availability of Concepts Lite; however, everything suggested here has been implemented in C++11, where Concepts Lite has been simulated with the help of generalized SFINAE for expressions.

III. Motivation and Scope
-------------------------

A "range" is an object that refers to a sequence of elements, conceptually similiar to a pair of iterators. One prime motivation for ranges is to give users a simpler syntax for calling algorithms. Rather than this:

    std::vector<int> v { /*...*/ };
    std::sort( v.begin(), v.end() );

Ranges would give us a pithier syntax:

    std::sort( v );

Allowing algorithms to take a single range object instead of separate begin and end iterators brings other benefits besides convenience. In particular:

  * It eliminates the possiblility of mismatched iterators.
  * It also opens the door to *range adaptors* which lazily transform or filter their underlying sequence in interesting ways.

Range adaptors are far more compelling than iterator adaptors due to the fact that only a single object, the range object, needs to be adapted; hence, adaptors can be easily chained to create lazy computational pipelines, as in the code below which sums the first 10 squares:

    int total = accumulate(view::iota(1) |
                           view::transform([](int x){return x*x;}) |
                           view::take(10), 0);

The standard defines the term "range" in [iterator.requirements.general]:

> [...] in general, a range `[i,j)` refers to the elements in the data structure starting with the element pointed to by `i` and up to but not including the element pointed to by `j`. Range `[i,j)` is valid if and only if `j` is reachable from `i`.

From the perspective of the standard library, and range *is* a pair of iterators. But there are other interesting ways to specify a range of elements:

* An iterator and a count of elements
* An iterator and a (possibly stateful) predicate that indicates when the range is exhausted.

Any other interesting range types, like an iterator and a sentinel value (e.g. a null-terminated string), can be shown to generalize to one of the three range types described above. Ideally, we would like our Range abstration to be general enough to accomodate the three different kinds of ranges since that would increase the applicability of the algorithms.

### Impact on the Standard

Although this paper does not offer specific wording for any additions to the standard, we imagine that proper support for ranges in C++ would involve changes to the following parts of the standard:

- New library-wide concepts related to ranges.
- New iterator algorithms for efficiently dealing with the new abstractions.
- Changes to existing algorithms to constrain the templates with concepts.
- Additional overloads of existing algorithms that accept ranges instead of pairs of iterators.
- Changes to the containers to allow containers to be constructed and assigned from ranges, and to allow range-based insert operations.
- A new library section for range adaptors, which are views of existing data that have been transformed or filtered and that compose with other views.
- General utilities for the construction of custom range adaptors.
- A minor change to the specification of the range-based `for` to make it more efficient and general.

Future papers will make specific recommendations for all of the above, modulo any feedback on the design presented here.

IV. Proposed Design
-------------------

The design space for ranges is surprisingly large. At one end of the spectrum lies [Boost.Range] [2] and [Adobe's ASL] [3] in which ranges are a thin abstraction on top of iterators, which remain the primitives that glue together data structures and algorithms. At the other end of the spectrum we find the [D Standard Library's std.range module] [4], in which ranges and operations on them are the primitives themselves.

This proposal picks a single point in this design space, and here we present the decisions that led to the selection of that point, along with guidelines to be applied to the standard library and the rationale for each choice.

### Design Goals

We feel that a well-designed range abstraction would:

* Allow algorithms to operate on the three kinds of ranges with low or no abstraction penalty and a minimum of syntactic noise,
* Allow range-based algorithms to share implementation with iterator-based algorithms,
* Make it easy for users to reason about the complexity and expense of range operations (e.g. How many passes over the data are made? Are the elements copied? etc.),
* Protect the user from lifetime issues,
* Make it straightforward for users to make their types model one of the range concepts.

It is helpful at this point to reflect on the success of C++11's range-based `for` loop. It succeeded because most of the types over which one would want to iterate already defined iterators and `begin`/`end` members. Cleanly and efficiently interoperating with and reusing the existing abstractions of the STL are critical to the success of any range extensions.

### High-Level Design

At the highest level, this paper proposes the addition of two related range concepts: Iterable and Range. *Iterable* is anything on which we can call `begin` and `end` to yield an iterator/sentinel pair. (Sentinels are described below.) The Iterable concept says nothing about the type's constructability or assignability. Range-based standard algorithms are constrained using the Iterable concept. Consider:

    int buf[5000];
    // Fill buf
    std::sort( buf );

`buf` denotes a range of elements, so we should be able to sort it, but native arrays are neither copyable nor assignable, so whatever range-like concept is used to constrain `sort`, it should not require those. The above line of code is equivalent to:

    using std::begin;
    using std::end;
    std::sort( begin( buf ), end( buf ) );

For an Iterable object `o`, the valid expressions are:

    auto b = begin( o ); // b models Iterator
    auto e = end( o );   // e models Regular
    bool f = (b == e);   // b and e model EqualityComparable

Algorithms will typically be implemented to take iterator/sentinel pairs, rather than the iterator/iterator pairs as they do now. A typical algorithm might look like:

    template<Iterator I, Regular S, /*...*/>
        requires EqualityComparable<I, S>
    I some_algo(I first, S last, /*...*/)
    {
        for(; first != last; ++first)
            /*...*/
        return first;
    }

    template<Iterable R, /*...*/>
    IteratorOf<R> some_algo( R & r, /*...*/ )
    {
        return some_algo( begin(r), end(r), /*...*/ );
    }

The *Range* concept is modeled by lightweight objects that denote a range of elements they don't own. A pair of iterators can easily model Range, whereas a `vector` cannot. Range, as opposed to Iterable, requires copyability and assignability. The algorithmic complexity of copy and assign is required to be O(1), as in: it does not depend on the number of elements in the Range.

The Range concept refines Iterable. In addition to the above valid expression, Range requires the following valid expressions for an object `o` of type `O`:

    // Constructable:
    auto o1 = o;
    auto o2 = std::move(o);
    O o3; // default-constructed, singular
    // Assignable:
    o2 = o1;
    o2 = std::move(o1);
    // Destructable
    o.~O::O();

The Range concept exists to give the range adaptors consistent and predictable semantics, and memory and performance characteristics. Since adaptor chains aggregate range objects, the objects must be copyable (or movable at the very least). To be consistent and predictible, Ranges (which are lightweight) are required. Any attempt to adapt an Iterable that is not a Range is first made one by taking the Iterable's begin and end.

The precise definitions of the suggested concepts are given in Section V, along with other supporting concepts that have proven useful while porting the algorithms.

The use of sentinels instead of iterators as an Iterable's bound is best understood by seeing how the three different kinds of ranges can be made to model the Iterable concept. Below is a sketch of how `begin` and `end` might work for each kind.

- **Pair of iterators**: An end iterator is a perfectly acceptable sentinel. Existing code that uses iterator pairs to call STL algorithms will continue working with no changes.
- **Iterator and predicate**: `begin(rng)` can return a normal iterator, `first`. `end(rng)` can return a sentinel `last` such that `first == last` returns the result of calling `last.predicate_(*first)`. See [Appendix 1](#appendix-1-sentinels-and-code-generation) for a discussion about the code generation benefits of letting the sentinel have a different type than the iterator.
- **Iterator and count**: `begin(rng)` can return an iterator `first` that bundles the underlying iterator with the count to the end. `end(rng)` can return an empty sentinel `last` such that `first == last` returns the result of `first.count_ == 0`. See [Appendix 4](#appendix-4-on-counted-ranges-and-efficiency) for a discussion of the performance implications of this design.

### Design Decisions, Guidelines, and Rationale

Below we present the decisions that led to the chosen high-level design, along with guidelines to be applied to the standard library and the rationale for each choice.

#### Iterator Operations are Primitive

To date, the most comprehensive effort to replace iterators with ranges as low-level primitives was undertaken by Andrei Alexandrescu when designing the D Standard Library. The result is, in the opinion of this author, a qualified success. See Appendix 3 for why I say "qualified".

This paper does not deeply explore the ranges-as-primitives approach taken by the D Standard Library. Such an approach would abandon a large investment in the iterator abstraction and create a schism within the standard library and in the community at large between range-based and iterator-based algorithms, which couldn't share code. We, the authors, consider such a schism unacceptable.

Although the concept of "sequence" undoubtably comes up more frequently in most domains than the "position in sequence" abstraction that iterators represent, completely banishing the concept of position leads to some awkward constructions. For example, trying to express an algorithm like `find` without the notion of "position" leads to the slightly contrived convention of returning a range. But which range to return? Indeed, the D Standard Library has as many `find` algorithms as there are answers to this question. (TODO reference)

Also, any algorithm that takes a range and a position within the range on which to do some operation (like `rotate`) becomes awkward and unwieldy without some notion of position.

Finally, iterators as primitives are provably more powerful than ranges. Any design that can be expressed with ranges can be expressed with iterators, but the converse is not true.

##### Position-Based Ranges

An alternate design is found in [James Touton's range library] [5], where ranges -- together with a new Position concept -- are the primitives. A Position, as its name suggests, represents a position in a range. Unlike an iterator, a position cannot be used to access the element at that position without the range into which it refers, nor can the position be advanced without the range.

This design has the following advantages:

* In making position a representable entity, it avoids the awkward constructions of D's range library.
* In requiring the range in order to dereference the position, it avoids all dangling iterator issues.
* In requiring the range in order to change the position, it makes range-checking trivial. This is a boon not just for debugability, but also for the design of certain range adaptors like filter and stride whose iterators need to know the end of the range so as not to walk past it.
* It permits a clean separation of element traversal and access, much like the suggested [cursor/property map abstraction] [11].

However, the design does not permit clean and efficient interoperation with the existing iterator abstraction. Bundling a range and a position into an iterator results in bloated iterators. All algorithms would need two implementations: one for ranges and one for iterators. For this reason, the position-based range design doesn't seem to meet our design goals.

#### Ranges Cannot Own Elements

As described above, a container is not a Range. It is, however, an Iterable. Distinguishing between the two makes it possible to be explicit about where copyability is required, and with what performance characteristics. Any Iterable that is not a Range is trivially convertible to a Range by simply taking its begin and end.

The distinction between Iterables and Ranges becomes critical when defining adaptor chains. On what data is the chain operating? Who owns it? How many times is it copied? What does code like the following mean?

    auto rng = v | view::reverse;

Is `rng` copyable, and if so, how expensive is the copy operation? If `v` is a `vector`, can `rng` safely outlive `v`? How about if `v` is just a pair of iterators? What happens when a user does `*rng.begin() = 42`? Is `v` mutated? How do the answers change if we replaced `v` with an rvalue expression? If a copy of `rng` is made, and an element is mutated through the copy, does the original `rng` object "see" the change?

By requiring that Ranges do *not* own their elements, and further requiring that range adaptors operate on and produce Ranges, we are able to answer these questions in a clear and consistent way. The result of a chain of range adaptors is always a lightweight object that is cheap to copy and assign (O(1) as opposed to O(N)), and that refers to elements whose lifetime is managed by some other object. Mutations of elements through the resulting Range object mutates the underlying sequence. Copies of the resulting range are aliases to the same elements, and mutations to the elements effect all the aliased ranges.

The downside of this design is that it is sometimes desirable to do this:

    // Try to adapt an rvalue container
    auto rng = vector<int>{1,2,3,4} | view::reverse; // OK?

As mentioned, the adaptors operate on and yield Ranges; other Iterables are made Ranges by first taking their begin and end. That is obviously unsafe in the code above since `rng` will be left holding invalid iterators into a container that no longer exists. Our solution is to disallow the above code. *It is illegal to adapt an rvalue non-Range.* (Adapting rvalue Ranges, however, is perfectly acceptable; indeed necessary if adaptor pipelines are to work.)

The alternative is for the rvalue container to be moved (or copied) into the adapted range and held by value. The resulting object would therefore no longer model Range; it would model Iterable. The authors feel that this weakening of the requirements on the return type makes it difficult to reason about the semantics and algorithmic complexity of range adaptors. The alternative is to first declare the container and create the adaptor separately.

#### Ranges Are Semiregular

We've already decided that Ranges (not Iterables) are copyable and assignable. They are, in the terminology of EoP and N3351, Semiregular types. It follows that copies are independent, even though the copies are both aliases of the same underlying elements. The ranges are independent in the same way that a copy of a pointer or an iterator is independent from the original. Likewise, iterators from two ranges that are copies of each other are also independent. When the src range goes out of scope, it does not invalidate an iterator into the dst range.

Semiregular also requires DefaultConstructible in N3351. We follow suit and require all Ranges to be DefaultConstructible. Although this complicates the implementation of some range types, it has proven useful in practice, so we have kept this requirement.

Why aren't Ranges Regular? Could they not also be EqualityComparable, such that `==` compares each element for equality? We have said that since Ranges are a kind of proxy, they are cheap to copy and assign. EoP has much to say about Regular types and the relationship between copy, assign, and equality comparison. If the first two operations are creating aliases and are O(1), it would be very strange for the third to do anything besides testing whether two ranges are aliases, and *very* strange for it to be O(N).

Also, there is nothing fundamentally wrong with a Range whose ValueType is not EqualityComparable, so requiring EqualityComparable with those semantics is overconstraining.

As a result, it seems undesirable to require an `operator==` that tests whether all the elements in two ranges are equal. That would make Range model the syntactic requirements of Regular without satisfying its axioms. The inconsistency in the algorithmic complexities of the three fundamental operations would simply be too confusing.

The question then is whether Range should require EqualityComparable with the "appropriate" semantics; that is, to test whether two Ranges refer to the *same* elements. Although such a requirement is appealing in theory, it has problems:

* It might conflict with users' expectations of what `rng1 == rng2` means.
* It is impossible to implement with those semantics in O(1) for some range types; for example, a filter range that stores a predicate. Functions are generally not EqualityComparable.

Another option is to allow Ranges to trivially model EqualityComparable by narrowly defining the domain over which the operation is valid. Iterators may only be compared if they refer into the same range. We can extend the reasoning to Ranges, which are logically little more than pairs of iterators. Taking this tack, we could allow a Range type to define its `operator==` as:

    rng1.begin() == rng2.begin() && rng1.end() == rng2.end()

The assumption being that the operation is invalid if `rng1` and `rng2` refer to different elements. Although principled (for some set of principles), such a definition is almost certain to lead users into undefined behavior-land.

As a result of the above, we have decided that the Range concept should not require EqualityComparable. Ranges are Semiregular, not Regular.

If a user would like to check to see if two ranges have elements that compare equal, we suggest the `equal` algorithm:

    if(std::equal(rng1, rng2))
        // ...

#### Iterators Cannot Outlive Their Ranges

Containers own their elements, so it is clear that the container must outlive the iterators it generates. It's not clear that the same must be true for ranges. After all, a range does not own its elements. In the simplest case, where a range is simple a pair of iterators, it's clear that the iterators *may* in fact outlive the range object. But is that always a safe bet?

It turns out that if we require that a range's iterators be permitted to outlive the range, a great many interesting range types become significantly more expensive at runtime. A good case study is the filter view.

A filter view takes a range and a predicate, and presents a view of the sequence that skips the elements for which the predicate is false. (The filter view can be thought of a lazy equivalent of the `copy_if` algorithm.) The existence of the `boost::filter_iterator` shows that such an iterator *can* be made such that it doesn't depend on a range, but at a cost. The `filter_iterator` stores:

 1. An iterator that indicates the current position in the underlying sequence.
 2. An iterator that indicates the end of the underlying sequence (needed by the increment operators to avoid falling off the end while searching for an element that satisfies the predicate).
 3. The predicate.

In today's STL, the begin and end iterators must have the same type, and they are both needed to call an algorithm. Thus, the information in (2) and (3) is duplicated. Also, the predicate may be expensive the copy, given the ease with which capture-by-value lambdas and `std::function`s can be created. When such iterators are composed with other kinds of views (e.g., a transformed, filtered view), the bloat compounds exponentially. (See [Indexed-Based Ranges] [10].)

By relaxing the constraint that a range's begin and end must have the same type, we can avoid the duplication, but the begin iterator still must hold everything, which is potentially expensive.

If, however, we could rely on the range object outliving the iterator, we can make the filter iterators smaller and lighter. The range object can hold the predicate and the underlying range's begin/end iterators. The filter view's iterator only needs to hold the current position and a pointer back to the range object.

#### An Iterable's End May Have a Different Type Than Its Begin

In today's STL, `c.begin()` must have the same type as `c.end()`. This is because the only kind of range the STL supports is a pair of iterators. However, we've given examples of other kinds of ranges we would like to support, such as an iterator and a predicate, and an iterator and a count. These kinds of ranges can already be supported by shoe-horning them into the pair-of-iterators mold, but at a cost (see Appendix 1). Loosening the constraints of the type of Iterable's end makes it possible to accomodate these other kinds of ranges with lower overhead.

Allowing "end-ness" to be encoded in the type system also eliminates the need to mock-up dummy end iterators like `std::istream_iterator` and `std::regex_iterator`, the logic of which is tricky to get right. What's more, it improves code generation for these kinds of ranges. With the use of dummy end iterators, information which is known at compile-time -- namely, that an iterator represents the end -- must be encoded into runtime information in the iterator itself. This robs the compiler of the information it needs to eliminate branches from the core loops of many algorithms. See Appendix 1 for an example of how sentinels can positively effect code generation.

When considering this choice for the range concept, it's helpful to think about how it would effect the algorithms. Consider `std::for_each`, which currently has this signature:

    template<class InputIterator, class Function>
    Function for_each(InputIterator first, InputIterator last, Function f)
    {
        for(; first != last; ++first)
            f(*first);
        return f;
    }

With sentinels, `for_each` might look like this:

    template<InputIterator I, Regular S, Function<ValueType<I>> F>
        requires EqualityComparable<I, S>
    F for_each(I first, S last, F f)
    {
        for(; first != last; ++first)
            f(*first);
        return f;
    }

None of the code in the algorithm had to change. No calling code would have to change either; this is a strictly backwards-compatible change. You might think that this opens a new category of programming errors where developers inadvertantly pass mismatched iterator/sentinel pairs. However, this algorithm signature is constrained with concept checks that ensures that `I` and `S` satisfied the cross-type EqualityComparable concept (see [N3351] [8]). See Appendix 2 for further discussion about iterator/sentinel cross-type EqualityComparability constraint.

To see the benefit of this design, imagine a sentinel type `null_sentinel`:

    // For determining whether an iterator refers to a null value:
    struct null_sentinel
    {
        template<Iterator I>
        friend bool operator==(I i, null_sentinel) { return 0 == *i; }
        // ... and friends
    };

    template<Iterator I>
    struct common_type<I, null_sentinel>
       ... see Appendix 2 ...

Now we can use `std::for_each` on null-terminated strings without needing to know the length of the string:

    std::for_each(argv[1], null_sentinel(), f);

Of course, all the algorithms would have overloads that also accept range arguments, so this can be further simplified to:

    std::for_each(null_terminated(argv[1]), f);

where `null_terminated(InputIterator)` returns a range `r` such that the `std::end(r)` is a `null_sentinel`.

##### Sentinels and Early Algorithm Termination

One excuse sometimes given for not using the standard algorithm is that they don't give the users a way to break out of them early. The use of sentinels makes that possible. Consider a sentinel constructed from both an end iterator and a predicate. Such a sentinel would compare equal to an iterator *either* when the iterator equals the end iterator *or* when the predicate evaluates to true. Using such a sentinel has the effect of terminating an algorithm early. For instance:

    // Process work items in a queue, allowing for a user interrupt
    std::queue<Work> q;
    std::function<void(Work const &)> user_interrupt = /*...*/;
    std::for_each( q | view::until(user_interrupt), f );

In the above, `view::until` is a range modifier that adds an extra termination constraint.

#### Algorithm Return Types are Changed to Accomodate Sentinels

Notice that in the due course of evaluating `std::for_each` with `null_sentinel` above, the position of the null terminator is found. This is potentially useful information that can easily be returned to the user. It is, in fact, a far more interesting and useful result that the `Function` that `for_each` currently returns. So a better signature for `for_each` should look like this:

    // Returns an InputIterator i such that (i == last) is true:
    template<InputIterator I, Regular S, Function<ValueType<I>> F>
        requires EqualityComparable<I, S>
    I for_each(I first, S last, F f);

In similar fashion, most algorithm get new return types when they are generalized to support sentinels. This is a source-breaking change in many cases. In some cases, like `for_each`, the change is unlikely to be very disruptive. In other cases it may be more so. Merely accepting the breakage is clearly not acceptable. We can image two ways to mitigate the problem:

1. Only change the return type when the types of the iterator and the sentinel differ. This leads to a slightly more complicated interface that may confuse users. It also greatly complicates generic code, which would need metaprogramming logic just to use the result of calling some algorithms. For this reason, this possibilty is not explored here.

2. Make the new return type of the algorithms implicitly convertible to the old return type. Consider `copy`, which currently returns the ending position of the output iterator. When changed to accomodate sentinels, the return type would be changed to something like `pair<I, O>`; that is, a pair of the input and output iterators. Instead of returning a `pair`, we could return a kind of pair that is implicitly convertible to its second argument. This avoids breakage in some, but not all, scenarios. This subterfuge is unlikely to go completely unnoticed.

3. Deliver the new standard library in a separate namespace that users must opt into. In that case, no code is broken until the user explicitly ports their code. The user would have to accomodate the changed return types then. An automated upgrade tool similiar to clang modernize (TODO REF) can greatly help here.

We the authors prefer (3). Our expectation is that the addition of concepts will occasion a rewrite of the STL to properly concept-ify it. The experience with C++0x Concepts taught us that baking concepts into the STL in a purely backward-compatible way is hard and leads to an unsatisfactory design with a proliferation of meaningless, purely syntactic concepts. The spirit of N3351 is to conceptify the STL is a meaningful way, even at the expense of minor breakage. Although the issue has yet to be discussed, muchless resolved, one likely solution would be to deliver a new STL in a separate namespace. Once that happens, it opens the door for other minor breaking changes, provided the benefits are deemed worthy.

#### Orthogonality of Traversal and Access Is Not Surfaced in the Iterator Concepts

The current iterator concept heirarchy ties together the traversal and access properties of iterators. For instance, no forward iterator may return an rvalue proxy when it is dereferenced; the ForwardIterator concept requires that unary `operator*` return an lvalue. And only random-access iterators can jump forward. There is no room in the heirarchy for, say, a random-access iterator that returns proxies.

This problem is not new to ranges; however, it has serious consequnces for lazy ranges that apply transformations to elements on the fly. If the transformation function does not return an lvalue, the range's iterator can model no concept stronger than InputIterator, even if the resulting iterator could in theory allow random access. The result in practice is that most range adaptors have the unfortunate effect of degrading the underlying range's category to Input, thereby limiting the number of algorithms it can be passed to -- often for no good reason.

Prior work as been done by [Abrahams et. al.] [9] to separate the traversal and access properties of iterators in a way that is backwards compatible. When formalizing the iterator concepts for a range library, should the new iterator concepts be used, or should we hew to the old, simpler concept heirarchy with its known limitations?

Although acknowledging that the problems are real, we opt not to address them at this time. That position may change in future papers.

#### Additional Overloads of the Algorithms

As should be obvious, this range proposal recommends adding additional overloads of the existing algorithms to allow them to work directly on Iterables. This is done in accordance with the following suggested guidelines:

- Any algorithm that currently operates on a range denoted by two iterators gets an overload where the two iterator argument are replaced with a single Iterable argument. (NOTE: This does *not* include the counted algorithms like `copy_n` that take an iterator and a count instead of two iterators.)
- All overloads of an algorithm, whether they take Iterables or separate iterator/sentinel arguments, are *semantically identical*. All overloads have the same return type. All evaluate eagerly. The expectation is that the Iterable-based overloads merely delegate to the iterator-based ones.
- As described above, algorithms that necessarily process their entire input sequence return the iterator position at the end in addition to whatever else they return. The purpose is to return potentially useful information that is computed as a side-effect of the normal execution of the algorithm. Exceptions to this design guideline are made when one of the following is true:
    * The algorithm might in some cases not consume the entire input sequence. (The point of this exception is to avoid forcing the algorithm to compute something that is not necessary for successful completion. For example, `find`.)
    * When the sole purpose of the algorithm is specifically to compute a single value; hence, changing the return type will necessarily break code using the C++11 version. Examples include `is_sorted` and `accumulate`.
- "Three-legged" iterator-based algorithms (i.e. algorithms that operate on two ranges, the second of which is specified by only a single iterator and is assumed to be long enough) now have 4 versions:
    1. The old three-legged iterator version,
    2. A four-legged version that uses the sentinel of the second sequence as an additional termination condition,
    3. A version that takes an Iterable and an Iterator (which dispatches to the three-legged iterator-based version),
       and
    4. A version that takes two Iterables (which dispatches to the four-legged iterator-based version).

  Note: Purely as an implementation consideration, overloads (iii) and (iv) above must be coded to avoid ambiguity when a native array is passed as the second parameter (where either an Iterable or an Iterator may appear). Arrays are Iterables, but if (iii) is naively coded to take an Iterator by value, a native array would also match, since native arrays decay into pointers.
- If an algorithm returns an iterator into an Iterable argument, the Iterable must be an lvalue. This is to avoid
  returning an iterator that is immediately made invalid. Conversely, if no iterator into an Iterable argument is
  returned, then the Iterable should be taken by ["universal reference"] [13].
- Algorithms that do not mutate their input sequence must also work when `initializer_list`s are used in place of Iterables.

#### Range-based for Loop is Changed to Accomodate Sentinels

The current range-base `for` loop assumes that a range's end has the same type as its begin. If the range algorithms work with Iterables, it's clear we would want the range-based `for` loop to, also.

The range-based for loop is currently specified as:

    {
        auto && __range = range-init;
        for ( auto __begin = begin-expr,
                   __end = end-expr;
              __begin != __end;
              ++__begin ) {
            for-range-declaration = *__begin;
            statement
        }
    }

To accomodate Iterables, the change would be as simple as:

    {
        auto && __range = range-init;
        auto __begin = begin-expr;
        auto __end = end-expr;
        for ( ; __begin != __end; ++__begin ) {
            for-range-declaration = *__begin;
            statement
        }
    }

This would be the only core language change required to fully support Iterables.

If a core language change is undesirable, it is possible to write a range adaptor that turns any Range into a BoundedRange. A BoundedRange is a refinement of Range where the types of `begin(r)` and `end(r)` are the same. Such a range adaptor is implementable if we are willing to accept a loss of performance and a degradation of the range's category to Forward. See Appendix 2 for a sketch of how such an adaptor would work.

#### Allow Mutable-Only Iterables

If an cv-unqualified type `T` models Iterable, then the type `T const` need not. This permits ranges that maintain
  mutable internal state; e.g., an `istream_range`.

Consider the performance short-comings of `istream_iterator<string>`. The iterator reads a string from an `istream` and must store it internally so it can be returned from `operator*`. That means that copying an `istream_iterator<string>` probably does a dynamic allocation. Copying iterators is not supposed to be expensive.

An alternative range-based design would be to define an `istream_range` class template:

    template<class T>
    class istream_range {
       T value_;
       istream * postr_;
    public:
        class iterator {
            istream_range * prng_;
        public:
            /*...*/
        };
        iterator begin() {/*...*/}
        iterator end() {/*...*/}
    };

In this design, the cached value lives in the range object, not in the iterator. The iterator merely stores a pointer back to the range. As the iterator is advanced, values are read from the stream and stored in the cache. Since the range object is mutated as it is iterated, it would be a lie to provide const overloads of `begin()` and `end()`.

The need for a range that is mutated in the course of iteration also came up in the design of a `view::flatten` adaptor that takes a range of ranges, and turns it into a single range. This adapted range also must mutate an internal cache. The adaptor is used to make Ranges monads, and is used in the implementation of [Range Comprehensions] [12], which are akin to Python's and Haskell's List Comprehensions. That discussion is beyond the scope of this document, however.

#### Range Adaptors are Lazy Algorithms

Consider the example given at the start of paper:

    int total = accumulate(view::iota(1) |
                           view::transform([](int x){return x*x;}) |
                           view::take(10), 0);

The semantics of the adaptors (the things in the `view::` namespace) are such that computations are only done on demand, when the resulting adapted range is iterated. In this case, the range pipeline expression does no work aside from setting up a computation. Only as `accumulate` executes is the sequence of integers generated and transformed.

All adaptors have these lazy semantics. This gives users the ability to reason about the algorithmic complexity of their programs. They can be certain that, if an underlying range is transformed and filtered and then passed to an algorithm, that the sequence will be traversed exactly once.

#### All Algorithms Accept Sentinels Even If They Need An End Iterator

Some algorithms like `reverse` really need an end iterator to do their job. One option would be to require users to pass an actual end iterator instead of a non-iterator sentinel. The other option is to accept a sentinel and do an O(N) probe for the end first. We opted for the later option. No such algorithms have complexity better than O(N), so such a probe doesn't affect the overall algorithmic complexity of the algorithm. And it saves the user the hassle of having to find the end herself before calling the algorithm. In short, it should be possible to `reverse` a null-terminated string *without* needing to call `strlen` first.

V. Concept Definitions
----------------------

The following concepts are proposed to constrain the standard library. The iterator concepts mentioned here are identical to those specified in N3351 except where specified.

### Iterator Concepts

The range concepts presented below build on the following iterator concepts. These are largely as found in N3351, with the addition of WeakIterator, Iterator, WeakOutputIterator and OutputIterator. The entire heirarchy is presented here for completeness.

    concept WeakIterator<WeaklyIncrementable I> =
        Copyable<I> &&
        requires(I i) {
            not_void(*i);
        };

A WeakIterator is a WeaklyIncrementable type that is both copyable and dereferencable. We add the additional constraint that the result of the dereference operator is not void. This is refined below by the addition of either Readable or Writable. Iterator and WeakIterator are added as concepts because it obviates the need for separate InputRange and OutputRange concepts.

    concept Iterator<WeakIterator I> =
        EqualityComparable<I>;

    concept WeakOutputIterator<WeakIterator I, typename T> =
        Writable<I, T>;

    concept OutputIterator<WeakIterator I, typename T> =
        EqualityComparable<I> && Writable<I, T>;

    concept WeakInputIterator<WeakIterator I> =
        Readable<I> &&
        requires(I i) {
            IteratorCategory<I>;
            Derived<IteratorCategory<I>, weak_input_iterator_tag>;
            Readable<decltype(i++)>;
        };

    concept InputIterator<WeakInputIterator I> =
        EqualityComparable<I> &&
        Derived<IteratorCategory<I>, input_iterator_tag>;

    concept ForwardIterator<InputIterator I> =
        Incrementable<I> &&
        Derived<IteratorCategory<I>, forward_iterator_tag>;

    concept BidirectionalIterator<ForwardIterator I> =
        Derived<IteratorCategory<I>, bidirectional_iterator_tag> &&
        requires decrement (I i, I j) {
            // Pre-decrement:
            I& == { ––i };
            axiom { is_valid(––i) => &––i == &i; }
            // Post-decrement:
            I == { i–– };
            axiom {
                is_valid(––i) <=> is_valid(i––);
                is_valid(i––) => (i == j => i–– == j);
                is_valid(i––) => (i == j => (i––, i) == ––j);
            }
        } &&
        axiom increment_decrement (I i, I j) {
            is_valid(++i) => (is_valid(––(++i)) && (i == j => ––(++i) == j));
            is_valid(––i) => (is_valid(++(––i)) && (i == j => ++(––i) == j));
        };

    concept RandomAccessIterator<BidirectionalIterator I> =
        TotallyOrdered<I> &&
        Derived<IteratorCategory<I>, random_access_iterator_tag> &&
        SignedIntegral<DistanceType<I>> &&
        // Difference:
        SizedIteratorRange<I, I> && // see below
        requires advance (I i, I j, DifferenceType<I> n) {
            // Addition:
            I& == { i += n };
            I == { i + n };
            I == { n + i };
            axiom {
                is_valid(advance(i, n) <=> is_valid(i += n);
                is_valid(i += n) => i += n == (advance(i, n), i);
                is_valid(i += n) => &(i += n) == &i;
                is_valid(i += n) => i + n == (i += n);
                // Commutativity of pointer addition
                is_valid(i + n) => i + n == n + i;
                // Associativity of pointer addition
                is_valid(i + (n + n)) => i + (n + n) == (i + n) + n;
                // Peano-like pointer addition:
                i + 0 == i;
                is_valid(i + n) => i + n == ++(i + (n – 1));
                is_valid(++i) => (i == j => ++i != j);
            }
            // Subtraction:
            I& == { i –= n };
            I == { i – n };
            axiom {
                is_valid(i += –n) <=> is_valid(i –= n);
                is_valid(i –= n) => (i –= n) == (i += –n);
                is_valid(i –= n) => &(i –= n) == &i;
                is_valid(i –= n) => (i – n) == (i –= n);
            }
        } &&
        requires subscript (I i, DifferenceType<I> n) {
            ValueType<I> = { i[n] };
            axiom {
                is_valid(i + n) && is_valid(*(i + n)) => i[n] == *(i + n);
            }
        };

### Iterator Range Concepts

    concept IteratorRange<Iterator I, Regular S> =
        EqualityComparable<I, S>;

    concept SizedIteratorRange<Iterator I, Regular S> =
        IteratorRange<I, S> &&
        requires difference (I i, S j) {
            DifferenceType<I> == { i - j };
            DifferenceType<I> == { j - i };
            DifferenceType<I> == { i - i };
            DifferenceType<I> == { j - j };
            SignedIntegral<DifferenceType>;
            Convertible<DistanceType, DifferenceType>;
            axiom {
                using C = CommonType<I, S>;
                is_valid(distance(i, j)) <=> is_valid(i – j) && is_valid(j – i) &&
                                             is_valid(C{i} - C{j}) && is_valid(C{j} - C{i});
                is_valid(i – j) => (i – j) >= 0 => i – j == distance(i, j);
                is_valid(i – j) => (i – j) < 0 => i – j == –distance(i, j);
                is_valid(j - j) => (j - j) == 0;

            }
        };

### Iterable Concepts

    concept Iterable<typename T> =
        requires(T t) {
            IteratorType<T>;
            SentinelType<T>;
            IteratorType<T> == { begin(t) };
            SentinelType<T> == { end(t) };
            IteratorRange<IteratorType, SentinelType>;
        }

    struct range_base
    {};

    // For exposition only:
    concept ContainerLike<Iterable T> =
        !Same<decltype(*begin(declval<T &>())), decltype(*begin(declval<T const &>()))>;

    // For exposition only:
    template<typename T>
    struct is_range_impl_
      : std::integral_constant<
            bool,
            Iterable<T> && (!ContainerLike<T> || Derived<T, range_base>)
        >
    {};

    // Specialize this if the default is wrong.
    template<typename T, typename Enable = void>
    struct is_range
      : conditional<
            is_same<T, remove_const_t<remove_reference_t<T>>>::value,
            is_range_impl_<T>,
            is_range<remove_const_t<remove_reference_t<T>>>
        >::type
    {};

    concept Range<Iterable T> =
        Semiregular<T> && True<is_range<T>::value>;

    // TODO Say something about SinglePass vs. MultiPass ranges, for the sake of
    // istream_range and flattened_range?


### Sized Iterable Concepts

The `SizedIterable` concept exists for the same reasons as `SizedIteratorRange`. There are some iterables that, though they are not random-access, know their size in O(1). A prime example is `std::list`. Another example is a counted view (ie., a range specified by an iterator and a count). Some algorithms can select a better implementation when the size of the range is known, even if the iterators don't allow random access.

    // For exposition only:
    concept SizedIterableLike<Iterable T> =
        requires(T t) {
            SizeType<T>;
            Integral<SizeType>;
            Convertible<SizeType, DifferenceType<IteratorType>>
            SizeType<T> == { size(t) };
        }

    // For exposition only:
    template<typename T>
    struct is_sized_iterable_impl_
      : std::integral_constant<
            bool,
            SizedIterableLike<T>()
        >
    {};

    // Specialize this if the default is wrong.
    template<typename T>
    struct is_sized_iterable
      : conditional<
            is_same<T, remove_const_t<remove_reference_t<T>>>::value,
            is_sized_iterable_impl_<T>,
            is_sized_iterable<remove_const_t<remove_reference_t<T>>>
        >::type
    {};

    concept SizedIterable<SizedIterableLike T> =
        True<is_sized_iterable<T>::value> &&
        requires(T t) {
            axiom {
                distance(begin(t), end(t)) == size(t);
            }
        };

VI. Technical Specifications
----------------------------

This section intentionally left blank.

VII. Future Directions
----------------------

- Range extensions to things like regex. Make it work with null-terminated strings, e.g..
- Discuss the pros and cons of tying this work with work on a concept-ified standard library (aka Concepts Lite TS2).
- Discuss the pros and cons of making this (and the concept-ified standard library) *strictly* backwards compatible, versus delivering the new, conceptified and range-ified standard library in a separate, versioned namespace (and what such a solution should look like).
- Discuss how an extension to the Concepts Lite proposal, implicit conversion to concept, bears on the Iterable/Range concepts and the way the algorithms are constrained.

VIII. Acknowledgements
----------------------

I would like to give special thanks to Sean Parent for his advice and feedback on early designs of the range library on which this proposal is based, in addition to his work on the Adobe Source Libraries from which this proposal has borrowed liberally.

Also deserving of special thanks is Andrew Sutton. His work on Concepts Lite and on the formulations of the algorithms as specified in N3351 has proven invaluable, and he has generously donated his time and expertise to expound on the ideas there and improve the quality of this proposal.

Chandler Carruth has also helped more than he probably knows. I am indebted to him for his support and perspective.

I would be remiss if I didn't acknowledge the foundational work of all the people whose ideas and sweat have gone into various range libraries and proposals in the past. They are too many to list, but I certainly benefited from the work of Dave Abrahams, Dietmar Kühl, Neil Groves, Thorsten Ottosen, Arno Schoedl, Daniel Walker, and Jeremy Seik.

Of course none of this work would be possible without Alex Stepanov's giant leap forward with the STL, or without Bjarne Stroustrup who gave Alex the instrument he needed to most clearly realize his vision.

IX. References
--------------

[2]: http://www.boost.org/libs/range "Boost.Range"
[3]: http://stlab.adobe.com/ "Adobe Source Libraries"
[4]: http://dlang.org/phobos/std_range.html "D Phobos std.range"
[5]: https://github.com/Bekenn/range "Position-Based Ranges"
[6]: https://github.com/sean-parent/sean-parent.github.com/wiki/presentations/2013-09-11-cpp-seasoning/cpp-seasoning.pdf "C++ Seasoning, Sean Parent"
[7]: http://www.github.com/ericniebler/range-v3 "Range v3"
[8]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2012/n3351.pdf "A Concept Design for the STL"
[9]: http://www.boost.org/libs/iterator/doc/new-iter-concepts.html "New Iterator Concepts"
[10]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2013/n3782.pdf "Indexed-Based Ranges"
[11]: http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1873.html "The Cursor/Property Map Abstraction"
[12]: http://ericniebler.com/2014/04/27/range-comprehensions/ "Range Comprehensions"
[13]: http://isocpp.org/blog/2012/11/universal-references-in-c11-scott-meyers "Universal References in C++11"
[14]: http://lafstern.org/matt/segmented.pdf "Segmented Iterators and Hierarchical Algorithms"
[15]: http://reviews.llvm.org/D2680 "Debug info: Support fragmented variables."

Appendix 1: Sentinels and Code Generation
-----------------------------------------

In this appendix we explore the effect of the use of sentinels on code generation. I'll show that allowing the type of the end iterator to differ from the begin can have a positive effect on the performance of algorithms. First, I'll note that nothing that can be done with sentinels cannot also be done with appropriately designed end iterators. Here, for instance, is the code for an iterator that can be used to adapt a null-terminated string to the STL. It is implemented with the help of the Boost.Iterators library:

    #include <cassert>
    #include <iostream>
    #include <boost/iterator/iterator_facade.hpp>

    struct c_string_range
    {
    private:
        char const *str_;
    public:
        using const_iterator = struct iterator
          : boost::iterator_facade<
                iterator
              , char const
              , std::forward_iterator_tag
            >
        {
        private:
            friend class boost::iterator_core_access;
            friend struct c_string_range;
            char const * str_;
            iterator(char const * str)
              : str_(str)
            {}
            bool equal(iterator that) const
            {
                return str_
                    ? (that.str_ == str_ ||
                         (!that.str_ && !*str_))
                    : (!that.str_ || !*that.str_);
            }
            void increment()
            {
                assert(str_ && *str_);
                ++str_;
            }
            char const& dereference() const
            {
                assert(str_ && *str_);
                return *str_;
            }
        public:
            iterator()
              : str_(nullptr)
            {}
        };
        c_string_range(char const * str)
          : str_(str)
        {
            assert(str_);
        }
        iterator begin() const
        {
            return iterator{str_};
        }
        iterator end() const
        {
            return iterator{};
        }
        explicit operator bool() const
        {
            return !!*str_;
        }
    };

    int c_strlen(char const *sz)
    {
        int i = 0;
        for(; *sz; ++sz)
            ++i;
        return i;
    }

    int range_strlen(
        c_string_range::iterator begin,
        c_string_range::iterator end)
    {
        int i = 0;
        for(; begin != end; ++begin)
            ++i;
        return i;
    }

The code traverses the sequence of characters without first computing its end. It does it by creating a dummy end iterator such that any time a real iterator is compared to it, it checks to see if the real iterator points to the null terminator. All the comparison logic is in the `c_string_range::iterator::equal` member function.

The functions `c_strlen` and `range_strlen` implement equivalent proceedures for computing the length of a string, the first using raw pointers and a check for the null terminator, the second using `c_string_range`'s STL iterators. The resulting optimized assembly code (clang 3.4 -O3 -DNDEBUG) generated for the two functions highlights the lost optimization opportunities.

<table border="0" cellpadding="0" cellspacing="0" style="border-collapse: collapse" bordercolor="#111111" width="607">
<tr><td><pre><code>c_strlen</code></pre></td><td><pre><code>range_strlen</code></pre></td></tr>
<tr><td valign="top"><pre><code>    pushl   %ebp
    movl    %esp, %ebp
    movl    8(%ebp), %ecx
    xorl    %eax, %eax
    cmpb    $0, (%ecx)
    je      LBB1_3
    xorl    %eax, %eax
    .align  16, 0x90
LBB1_2:
    cmpb    $0, 1(%ecx,%eax)
    leal    1(%eax), %eax
    jne     LBB1_2
LBB1_3:
    popl    %ebp
    ret</code></pre></td><td><pre><code>    pushl   %ebp
    movl    %esp, %ebp
    pushl   %esi
    leal    8(%ebp), %ecx
    movl    12(%ebp), %esi
    xorl    %eax, %eax
    testl   %esi, %esi
    movl    8(%ebp), %edx
    jne     LBB2_4
    jmp     LBB2_1
    .align  16, 0x90
LBB2_8:
    incl    %eax
    incl    %edx
    movl    %edx, (%ecx)
LBB2_4:
    testl   %edx, %edx
    jne     LBB2_5
    cmpb    $0, (%esi)
    jne     LBB2_8
    jmp     LBB2_6
    .align  16, 0x90
LBB2_5:
    cmpl    %edx, %esi
    jne     LBB2_8
    jmp     LBB2_6
    .align  16, 0x90
LBB2_3:
    leal    1(%edx,%eax), %esi
    incl    %eax
    movl    %esi, (%ecx)
LBB2_1:
    movl    %edx, %esi
    addl    %eax, %esi
    je      LBB2_6
    cmpb    $0, (%esi)
    jne     LBB2_3
LBB2_6:
    popl    %esi
    popl    %ebp
    ret</code></pre></td></tr>
</table>

The author has never seen code like `c_string_range` in the wild. Typically, when users want to use an STL algorithm on a C-style string, they call `strlen` to find the end first. (This is what the standard regex algorithms do when passed C-style strings.) That traverses the string an extra time needlessly. Also, such a trick is not possible for input sequences like those traversed by `std::istream_iterator` that consume their input.

Rather than mocking up a dummy end iterator with a computationally expensive equality comparison operation, we can use a sentinel type that encodes end-ness in its type. Below is an example from the [Range-v3 library] [7], which uses a `range_facade` class template to generate iterators and sentinels from a simple range-like interface:

    using namespace ranges;
    struct c_string_iterable
      : range_facade<c_string_iterable>
    {
    private:
        friend range_core_access;
        char const *sz_;
        char const & current() const { return *sz_; }
        void next() { ++sz_; }
        bool done() const { return *sz_ == 0; }
        bool equal(c_string_iterable const &that) const
        { return sz_ == that.sz_; }
    public:
        c_string_iterable() = default;
        c_string_iterable(char const *sz)
            : sz_(sz) {}
    };

    // Iterable-based
    int iterable_strlen(
        range_iterator_t<c_string_iterable> begin,
        range_sentinel_t<c_string_iterable> end)
    {
        int i = 0;
        for(; begin != end; ++begin)
            ++i;
        return i;
    }

The assembly generated for `iterable_strlen` is nearly identical to that for the hand-coded `c_strlen`:

        pushl   %ebp
        movl    %esp, %ebp
        movl    8(%ebp), %ecx
        xorl    %eax, %eax
        cmpb    $0, (%ecx)
        je      LBB1_4
        leal    8(%ebp), %edx
        .align  16, 0x90
    LBB1_2:
        cmpb    $0, 1(%ecx,%eax)
        leal    1(%eax), %eax
        jne     LBB1_2
        addl    %eax, %ecx
        movl    %ecx, (%edx)
    LBB1_4:
        popl    %ebp
        ret

The difference is due to the fact that the sentinel has a different type than the iterator, so that the expression `begin != end` can be optimized into `*begin == 0`. Compare this to the `range_strlen` case shown above. In that case, `begin == end` is comparing two objects of the same type, and since either `begin` or `end` could be a sentinel -- or both, or neither -- the compiler can't elide the extra checks without extra information from the surrounding calling context, which isn't always available; hence, the worse code gen.

In addition to the performance impact, the complexity of implementing a correct `operator==` for an iterator with a dummy sentinel can present problems. Chandler Carruth reports that such comparison operators have been a rich source of bugs for Google.

Appendix 2: Sentinels, Iterators, and the Cross-Type EqualityComparable Concept
-------------------------------------------------------------------------------

This appendix describes the theoretical justification for sentinels from the perspective of the STL concepts as set out in [N3351] [8]. In that paper, the foundational concept EqualityComparable is described in depth, not only its syntactic constraints but also its semantic axioms. It it not enough that the syntax `a == b` compiles. It has to be a meaningful comparison. Here I explain why I believe it is meaningful to compare an iterator with a sentinel of a different type for equality.

In the expression `x == y`, where `x` and `y` have different types, the EqualityComparable concept requires that the types of both `x` and `y` must themselves be EqualityComparable, and there must be a common type to which they can both be converted, and that type must also be EqualityComparable. Think of comparing a `char` with a `short`. It works because both `char` and `short` are EqualityComparable, and because they can both be converted to an `int` which is also EqualityComparable.

Iterators are comparable, and sentinels are trivially comparable (they always compare equal). The tricky part is the common type requirement. Logically, every iterator/sentinel pair has a common type that can be constructed as follows: assume the existence of a new iterator type `I` that is a tagged union that contains *either* an iterator *or* a sentinel. When an iterator is compared to a sentinel, it behaves semantically as if both the iterator and the sentinel were first converted to two objects of type `I` — call them `lhs` and `rhs` — and then compared according to the following truth table:

LHS IS SENTINEL ? | RHS IS SENTINEL ? | LHS == RHS ?
----------------- | ----------------- | ------------
`true`            | `true`            | `true`
`true`            | `false`           | `done(rhs.iter)`
`false`           | `true`            | `done(lhs.iter)`
`false`           | `false`           | `lhs.iter == rhs.iter`

In Appendix 1, there is an implementation of `c_string_range` whose iterator's `operator==` is a procedure for evaluating this truth table. That’s no coincidence; that was a special case of this more general construction.

In summary, for every iterator/sentinel pair, we can construct a common iterator type that implements an equivalent procedure for computing equality. The existence of this common type is what allows iterator/sentinel pairs satisfy the EqualityComparable requirement.

As a final note, the Range v3 library has a general implementation of this common iterator type as a paramterized type, and appropriate specializations of `std::common_type` that allow the constrained algorithms type type-check correctly. It works well in practice, both for the purpose of type-checking the algorithms and for adapting ranges with iterator/sentinel pairs to old code that expects the begin and end of a range to have the same type.

Appendix 3: D Ranges and Algorithmic Complexity
-----------------------------------------------

TODO Discussion of the is_word_boundary example.

Appendix 4: On Counted Ranges and Efficiency
--------------------------------------------

The three types of ranges that we would like the Iterable concept to be able to efficiently model are:

1. Two iterators
2. An iterator and a predicate
3. An iterator and a count

The Iterator/Sentinel abstraction is what makes it possible for the algorithms to handle these three cases with uniform syntax. However, the third option presents challenges when trying to make some algorithms optimally efficient.

Counted ranges, formed by specifying a position and a count of elements, have iterators -- as all Iterables do. The iterators of a counted range must know the range's extent and how close they are to reaching it. Therefore, the counted range's iterators must store both an iterator into the underlying sequence and a count -- either a count to the end or a count from the front. Here is one potential design:

    class counted_sentinel
    {};

    template<WeakIterator I>
    class counted_iterator
    {
        I it_;
        DistanceType<I> n_; // distance to end
    public:
        // ... constructors...
        using iterator_category =
            typename iterator_traits<I>::iterator_category;
        decltype(auto) operator*() const
        {
            return *it_;
        }
        counted_iterator & operator++()
        {
            ++it_;
            --n_;
            return *this;
        }
        friend bool operator==(counted_iterator const & it,
                               counted_sentinel)
        {
            return it.n_ == 0;
        }
        // ... other operators...
    };

    template<WeakIterator I>
    class counted_range
    {
        I begin_;
        DistanceType<I> count_;
    public:
        // ... constructors ...
        counted_iterator<I> begin() const
        {
            return {begin_, count_};
        }
        counted_sentinel end() const
        {
            return {};
        }
    };

    template<WeakIterator I>
    struct common_type<counted_iterator<I>, counted_sentinel>
        // ... see Appendix 2 ...

There are some noteworthy things about the code above. First, `counted_iterator` bundles an iterator and a count. Right off, we see that copying counted iterators is going to be more expensive, and iterators are copied frequently. A mitigating factor is that the sentinel is empty. Passing a `counted_iterator` and a `counted_sentinel` to an algorithm copies as much data as passing an iterator and a count. When passed separately, the compiler probably has an easier time fitting them in registers, but some modern compilers are capable passing the members of a struct in registers (see [this LLVM commit][15] for example, TODO more references for the "well-known" Scalar Replacement of Aggregates compiler optimization).

Also, incrementing a counted iterator is expensive: it involves incrementing the underlying iterator and decrementing the internal count. To see why this is potentially expensive, consider the trivial case of passing a `counted_iterator<list<int>::iterator>` to `advance`. That counted iterator type is bidirectional, and `advance` must increment it *n* times:

    template<BidirectionalIterator I>
    void advance(I & i, DistanceType<I> n)
    {
        if(n >= 0)
            for(; n != 0; --n)
                ++i;
        else
            for(; n != 0; ++n)
                --i;
    }

Notice that for each `++i` or `--i` here, *two* increments or decrements are happening when `I` is a `counted_iterator`. This is sub-optimal. A better implementation for `counted_iterator` is:

    template<BidirectionalIterator I>
    void advance(counted_iterator<I> & i, DistanceType<I> n)
    {
        i.n_ -= n;
        if(n >= 0)
            for(; n != 0; --n)
                ++i.it_;
        else
            for(; n != 0; ++n)
                --i.it_;
    }

This has a noticeable effect on the generated code. As it turns out, `advance` is one of the relatively few places in the standard library where special handling of `counted_iterator` is needed. Let's examine some algorithms to see why that's the case.

### Single-Pass Algorithms with Counted Iterators

First, let's look at a simple algorithm like `for_each` that makes exactly one pass through its input sequence:

    template<InputIterator I, Regular S, Function<ValueType<I>> F>
        requires EqualityComparable<I, S>
    I for_each(I first, S last, F f)
    {
        for(; first != last; ++first)
            f(*first);
        return first;
    }

When passed counted iterators, at each iteration of the loop, we do an increment, a decrement (for the underlying iterator and the count), and a comparison. Let's compare this against a hypothetical `for_each_n` algorithm that takes the underlying iterator and the count separately. It might look like this:

    template<InputIterator I, Function<ValueType<I>> F>
    I for_each_n(I first, DifferenceType<I> n, F f)
    {
        for(; n != 0; ++first, --n)
            f(*first);
        return first;
    }

For the hypothetical `for_each_n`, at each loop iteration, we do an increment, a decrement, and a comparison. That's exactly as many operations as `for_each` does when passed counted iterators. So a separate `for_each_n` algorithm is probably unnecessary if we have sentinels and `counted_iterator`s. This is true for any algorithm that makes only one pass through the input range. That turns out to be a lot of algorithms.

### Multi-Pass Algorithms with Counted Iterators

There are other algorithms that make more than one pass over the input sequence. Most of those, however, use `advance` when they need to move iterators by more than one hop. Once we have specialized `advance` for `counted_iterator`, those algorithms that use `advance` get faster without any extra work.

Consider `partition_point`. Here is one example implementation, taken from libc++ and ported to Concepts Lite and sentinels:

    template<ForwardIterator I, Regular S, Predicate<ValueType<I>> P>
        requires EqualityComparable<I, S>
    I partition_point(I first, S last, P pred)
    {
        DifferenceType<I> len = distance(first, last);
        while (len != 0)
        {
            DifferenceType<I> l2 = len / 2;
            I m = first;
            advance(m, l2);
            if (pred(*m))
            {
                first = ++m;
                len -= l2 + 1;
            }
            else
                len = l2;
        }
        return first;
    }

Imagine that `I` is a forward `counted_iterator` and `S` is a `counted_sentinel`. If the library does not specialize `advance`, this is certainly inefficient. Every time `advance` is called, needless work is being done. Compare it to a hypothetical `partition_point_n`:

    template<ForwardIterator I, Predicate<ValueType<I>> P>
    I partition_point_n(I first, DifferenceType<I> len, P pred)
    {
        while (len != 0)
        {
            DifferenceType<I> l2 = len / 2;
            I m = first;
            advance(m, l2);
            if (pred(*m))
            {
                first = ++m;
                len -= l2 + 1;
            }
            else
                len = l2;
        }
        return first;
    }

The first thing we notice is that `partition_point_n` doesn't need to call `distance`! The more subtle thing to note is that calling `partition_point_n` with a raw iterator and a count saves about O(N) integer decrements over the equivalent call to `partition_point` with `counted_iterator`s ... unless, of course, we have specialized the `advance` algorithm as shown above. Once we have, we trade the O(N) integer decrements for O(log N) integer subtractions. That's a big improvement.

But what about the O(N) call to `distance`? Actually, that's easy, and it's the reason why the SizedIteratorRange concept exists. `counted_iterator` stores the distance to the end. So the distance between a `counted_iterator` and a `counted_sentinel` (or between two `counted_iterators`) is known in O(1) *regardless of the iterator's category*. The SizedIteratorRange concept tests whether an iterator `I` and a sentinel `S` can be subtracted to get the distance. This concept is modeled by random-access iterators by their nature, but also by counted iterators and their sentinels. The `distance` algorithm is specialized for SizedIteratorRange, so it is O(1) for counted iterators.

With these changes, we see that `partition_point` with counted iterators is very nearly as efficient a hypothetical `partition_point_n` would be, and we had to make no special accomodations. Why can't we make `partition_point` *exactly* as efficient as `partition_point_n`? When `partition_point` is called with a counted iterator, it also *returns* a counted iterator. Counted iterators contain two datums: the position and distance to the end. But when `partition_point_n` returns just the position, it is actually computing and returning less information. Sometimes users doesn't need the extra information. But sometimes, after calling `partition_point_n`, the user might want to pass the resulting iterator to another algorithm. If *that* algorithm calls `distance` (like `partition_point` and other algorithms do), then it will be O(N). With counted iterators, however, it's O(1). So in the case of `partition_point`, counted iterators cause the algorithm to do O(log N) extra work, but it sometimes saves O(N) work later.

To see an example, imagine a trivial `insertion_sort` algorithm:

// TODO BUGBUG this doesn't quite illustrate the point I'm trying to make. Imagine the result of upper_bound is *then* passed to an algorithm that calls distance. That's when counted iterators come out ahead.

    template<ForwardIterator I, Regular S>
        requires EqualityComparable<I, S> && Sortable<I> // from N3351
    void insertion_sort(I begin, S end)
    {
        for(auto it = begin; it != end; ++it)
        {
            auto insertion = upper_bound(begin, it, *it);
            rotate(insertion, it, next(it));
        }
    }

Imagine that `I` is a `counted_iterator`. The first thing `upper_bound` does is call `distance`. Making `distance` O(1) for `counted_iterator`s saves N calls of an O(N) algorithm. To get comparable performance for an equivalent procedure in today's STL, users would have to write a separate `insertion_sort_n` algorithm that dispatches to an `upper_bound_n` algorithm -- that they would also need to write themselves.

### Counted Algorithms with Counted Iterators

We've seen that regular algorithms with counted iterators can be made nearly as efficient as dedicated counted algorithms, and that sometimes we are more than compensated for the small performance loss. All is not roses, however. There are a number of *counted algorithms* in the standard (the algorithms whose names end with `_n`). Consider `copy_n`:

    template<WeakInputIterator I, WeakOutputIterator<ValueType<I>> O>
    pair<I, O> copy_n(I in, DifferenceType<I> n, O out)
    {
        for(; n != 0; ++in, ++out, --n)
            *out = *in;
        return {in, out};
    }

(We've changed the return type of `copy_n` so as not to lose information.) If `I` is a counted iterator, then for every `++in`, an increment and a decrement are happening, and in this case the extra decrement is totally unnecessary. For *any* counted (i.e., `_n`) algorithm, something special needs to be done to keep the performance from degrading when passed counted iterators.

The algorithm author has two options here, and neither of them is ideal.

**Option 1: Overload the algorithm**

The following is an optimized version of `copy_n` for counted iterators:

    template<WeakInputIterator I, WeakOutputIterator<ValueType<I>> O>
    pair<I, O> copy_n(counted_iterator<I> in, DifferenceType<I> n, O out)
    {
        for(auto m = it.n_ - n; it.n_ != m; ++in.i_, --in.n_, ++out)
            *out = *in;
        return {in, out};
    }

Obviously, creating an overload for counted iterators is unsatisfying.

**Option 2: Separate the iterator from the count**

This option shows how a library implementer can write just one verion of `copy_n` that is automatically optimized for counted iterators. First, we need to provide two utility functions for unpacking and repacking counted iterators:

    template<WeakIterator I>
    I uncounted(I i)
    {
        return i;
    }

    template<WeakIterator I>
    I uncounted(counted_iterator<I> i)
    {
        return i.it_;
    }

    template<WeakIterator I>
    I recounted(I const &, I i, DifferenceType<I>)
    {
        return i;
    }

    template<WeakIterator I>
    counted_iterator<I> recounted(counted_iterator<I> const &j, I i, DifferenceType<I> n)
    {
        return {i, j.n_ - n};
    }

With the help of `uncounted` and `recounted`, we can write an optimized `copy_n` just once:

    template<WeakInputIterator I, WeakOutputIterator<ValueType<I>> O>
    pair<I, O> copy_n(I in_, DifferenceType<I> n_, O out)
    {
        auto in = uncounted(in_);
        for(auto n = n_; n != 0; ++in, --n, ++out)
            *out = *in;
        return {recounted(in_, in, n_), out};
    }

This version works optimally for both counted and non-counted iterators. It is not a thing of beauty, however. It's slightly annoying to have to do the `uncounted`/`recounted` dance, but it's mostly needed only in the counted algorithms.

As a final note, the overload of `advance` for counted iterators can be eliminated with the help of `uncounted` and `recounted`. After all, `advance` is a counted algoirhtm.

**Summary**

In short, counted iterators are not a perfect abstraction. There is some precedent here. The iterators for `deque`, and for any segmented data structure, are known to be inefficient (see [Segmented Iterators and Heirarchical Algorithms] [14], Austern 1998). The fix for that problem, new iterator abstractions and separate heirarchical algorithm implementations, is invasive and is not attempted in any STL implementation we are aware of. In comparison, the extra complications that come with counted iterators seems quite small. For segmented iterators, the upside was the simplicity and uniformity of the Iterator abstraction. In the case of counted ranges and iterators, the upside is the simplicity and uniformity of the Iterable concept. All you need to know to use it is `begin(rng)` and `end(rng)`.

Appendix 5: Drive-By Improvements to the Standard Algorithms
------------------------------------------------------------

As we are making changes to the standard algorithms, not all of which are strictly source compatible, here are some other drive-by changes that we might consider making. The changes suggested below have nothing to do with ranges *per se*, but they increase the power and uniformity of the STL and they have proven useful in the Adobe Source Library, so we might consider taking all these changes in one go.

### Higher-Order Algorithms Should Take Invokables Instead of Functions

Some algorithms like `for_each` are higher-order; they take functions as parameters. In N3351, they are constrained with the `Function` concept which, among other things, requires that its parameters can be used to form a valid callable expression `f(a)`.

However, consider a class `S` with a member function `Do`, like:

    class S {
    public:
        void Do() const;
    };

If we have a `vector` of `S` objects and we want to `Do` all of them, this is what we need to do:

    for_each( v, [](auto & s) { s.Do(); });

or, more concisely with a `bind` expression:

    for_each( v, bind(&S::Do, _1) );

Note that `bind` is specified in terms of a hypothetical INVOKE utility in [func.require]. Wouldn't it be more convenient if all the algorithms were required to merely take INVOKE-able things -- that is, things that can be passed to `bind` -- as arguments, instead of Functions? Then we can express the above call to `for_each` more concisely as:

    for_each( v, &S::Do );

We can define an `invokable` utility function as:

    template<typename R, typename T>
    auto invokable(R T::* p) const -> decltype(std::mem_fn(p))
    {
        return std::mem_fn(p);
    }

    template<typename T, typename U = decay_t<T>>
    auto invokable(T && t) const -> enable_if_t<!is_member_pointer<U>::value, T>
    {
        return std::forward<T>(t);
    }

    template<typename F>
    using invokable_t = decltype(invokable(std::declval<F>()));

We can define an Invokable concept as:

    concept Invokable<Semiregular F, typename... As> =
        Function<invokable_t<F>, As...> &&
        requires (F f, As... as) {
            InvokableResultOf<F, As...>;
            InvokableResultOf<F, As...> == invokable(f)(as...);
        };

The Invokakble concept can be used to constrain algorithms instead of the Function concept. The algorithms would need to apply `invokable` to each Invokable argument before invoking it.

This is pure extension and would break no code.

### Algorithms Should Take Invokable Projections

- Wherever appropriate, algorithms should optionally take INVOKE-able *projections* that are applied to each element
  in the input sequence(s). This, in effect, allows users to trivially transform each input sequence for the sake
  of that single algorithm invocation. The reason for projections is described in
  [Sean Parent's "C++ Seasoning" talk] [6] on slide 38.
- Algorithms that take two input sequences should (optionally) take two projections.
- For algorithms that optionally accept functions/predicates (e.g. `transform`, `sort`), projection arguments
  positionally follow functions/predicates. There are no algorithm overloads that allow the user to specify the
  projection without also specifying a predicate, even if the default would suffice. This is to reduce the
  number of overloads and also to avoid any potential for ambiguity.

The Adobe Source Libraries (ASL) pioneered the use of "projections" to make the algorithms more powerful and expressive by increasing interface symmetry. Sean Parent gives a motivating example in his ["C++ Seasoning" talk] [6], on slide 38. With today's STL, when using `sort` and `lower_bound` together with user-defined predicates, the predicate must sometimes differ. Consider:

    std::sort(a, [](const employee& x, const employee& y)
                 { return x.last < y.last; });
    auto p = std::lower_bound(a, "Parent", [](const employee& x, const string& y)
                                           { return x.last < y; });

Notice the different predicates used in the invocations of `sort` and `lower_bound`. Since the predicates are different, there is a chance they might get out of sync leading to subtle bugs.

By introducing the use of projections, this code is simplified to:

    std::sort(a, std::less<>(), &employee::last);
    auto p = std::lower_bound(a, "Parent", std::less<>(), &employee::last);

Every element in the input sequence is first passed through the projection `&employee::last`. As a result, the simple comparison predicate `std::less<>` can be used in both places.

No effort was made in ASL to use projections consistently. This proposal bakes them in everywhere it makes sense.

#### Projections versus Range Transform View

In a sense, the use of a projection parameter to an algorithm is similar to applying a transform view directly to a range. For example, calling `std::find` with a projection is similar to applying a transform to a range and calling without the projection:

    auto it = std::find( a, 42, &employee::age );

    auto a2 = a | view::transform( &employee::age );
    auto it2 = std::find( a2, 42 );

Aside from the extra verbosity of the view-based solution, there are two meaningful differences: (1) The type of the resulting iterator is different; `*it` refers to an `employee` whereas `*it2` refers to an `int`. And (2) if the transform function returns an rvalue, then the transformed view cannot model a forward sequence due to the requirements on the ForwardIterator concept. The result of applying a transform view is an Input range unless the transform function returns an lvalue. The projection-based interface suffers no such degredation of the iterator category. For those reasons, range transform adapters are not a replacement for projection arguments to algorithms.

See [Algorithm Implementation with Projections](#algorithm-implementation-with-projections) for a discussion of how projections effect the implementation.

The addition of projection arguments to the algorithms is pure extension.

Appendix 6: Implementation Notes
--------------------------------

### On Distinguishing Ranges from Non-Range Iterables

The design of the range library depends on the ability to tell apart Ranges from Iterables. Ranges are lightweight objects that refer to elements they do not own. As a result, they can guarantee O(1) copyability and assignability. Iterables, on the other hand, may or may not own their elements, and so cannot guarantee anything about the algorithmic complexity of their copy and assign operations. Indeed, an Iterable may not be copyable at all: it may be a native array or a `vector` of move-only types.

But how to tell Ranges apart from Iterables? After all, whether an Iterable owns its elements or not is largely a semantic difference with no purely syntactic way to differentiate. Well, that's amost true...

It turns out that there is a reasonably good heuristic we can use to tell Iterables and Ranges apart. Imagine that we have some Iterable type `T` that is either a container like `list`, `vector`, or a native array; or else it's a Range like `pair<int*,int*>`. Then we can imagine taking iterators to `T` and `const T`, dereferencing them, and comparing the resulting reference types. The following table gives the results we might expect to find.

Expression                      |  Container            |   Range
--------------------------------|-----------------------|-----------------------
`*begin(declval<T&>())`         | `value_type &`        | `[const] value_type &`
`*begin(declval<const T&>())`   | `const value_type &`  | `[const] value_type &`

Notice how containers and ranges differ in the way a top-level cv-qualifier effects the reference type. Since a range is a proxy to elements stored elsewhere, a top-level `const` qualification on the *range* object typically has no effect at all on its iterator's reference type. But that's not true for a container that owns its elements.

We can use this to build an `is_range` traits that gives a pretty good guess whether an Iterable type is a range or not. This trait can be used to define the Range concept. Obviously since it's a trait, users are free to specialize it if the trait guesses wrong.

Some people want their range types to behave like containers with respect to the handling of top-level `const`; that is, they would like their ranges to be designed such that if the range object is `const`, the range's elements cannot be mutated through it. There is nothing in this design that precludes that, but it does require the developer of such a range to specialize the `is_range` trait. If anything, the default behavior of the trait can be seen as gentle encouragement to handle top-level `const` in a way that is consistent with ranges' nature as a lightweight proxy.

As an added convenience, we can provide a class, `range_base`, from which users can inherit as another way of opting in to "range-ness". The `is_range` trait can test for inheritance from `range_base` as an extra test. This would save the people the trouble of opening the `std` namespace to specialize the `is_range` trait on the rare occasions that that is necessary.

If the `is_range` traits erroneously reports `false` for a type that is actually a range, then the library errs on the side of caution and will prevent the user from using rvalues of that type in range adaptor pipelines. If, on the other hand, the `is_range` trait gets the answer wrong for a type that is actually a container, the container ends up being copied or moved into range adaptors. This is a performance bug, and it may give surprising results at runtime if the original container doesn't get mutated when the user thinks it should. It's not a memory error, though.

### Native Arrays and Ambiguity

TODO discuss how to properly constrain an overload set that can take either an Iterable or an Iterator, when users might pass a native array.

### Algorithm Implementation with Projections

Rather than requiring additional overloads, the additions of projection arguments has very little cost to library implementers. The use of function template default parameters obviates the need for overloads. For instance, `find` can be defined as:

    template<InputIterator I, Regular S, typename V, Invokable<ValueType<I>> Proj = identity>
        requires EqualityComparable<I, S> &&
                 EqualityComparable<V, InvokableResultOf<Proj, ValueType<I>>>
    I find(I first, S last, V const & val, Proj proj = Proj{})
    {
        /* ... */
    }

### Algorithms That Need An End Iterator

Some algorithms need to know the real physical end of the input sequence so that the sequence can be traversed backwards, like `reverse`. In those cases, it's helpful to have an algorithm `advance_to` that takes an iterator and a sentinel and returns a real end iterator. `advance_to` looks like this:


    template<Iterator I, Regular S>
        requires IteratorRange<I, S>
    I advance_to( I i, S s )
    {
        while(i != s)
            ++i;
        return i;
    }

    template<Iterator I, Regular S>
        requires SizedIteratorRange<I, S>
    I advance_to( I i, S s )
    {
        advance( i, s - i );
        return i;
    }

    template<Iterator I>
    I advance_to( I, I s )
    {
        return s;
    }

When the sentinel is actually an iterator, we already know where the end is so we can just return it. Notice how we handle SizedIteratorRanges specially and dispatch to `advance` with a count. Appendix 4 shows how `advance` is optimized for counted iterators. By dispatching to `advance` when we can, we make `advance_to` faster for counted iterators, too.

With `advance_to` we can implement `reverse` generically as:

    template<BidirectionalIterator I, Regular S>
        requires EqualityComparable<I, S> && Permutable<I>
    I reverse( I first, S last_ )
    {
        I last = advance_to( first, last_ ), end = last;
        while( first != last )
        {
            if( first == --last )
                break;
            iter_swap( first, last );
            ++first;
        }
        return end;
    }

Since this algorithm necessarily computes the end of the sequence if it isn't known already, we return it.
